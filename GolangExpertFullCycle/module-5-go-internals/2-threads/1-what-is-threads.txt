=====================================
  O QUE É UMA THREAD?
=====================================
- É a menor unidade de execução que o SO pode gerenciar.
- Uma "linha de execução" ou um "caminho" que o código pode seguir dentro de um processo.
- Um processo começa com uma única thread (a "main thread") e pode criar outras para executar tarefas em paralelo ou de forma concorrente.


-------------------------------------
  PROCESSOS vs. THREADS (RECAP)
-------------------------------------

  RECURSO             | PROCESSOS                     | THREADS
--------------------------------------------------------------------------
  Memória             | ISOLADA (cada um tem a sua)   | COMPARTILHADA (dentro do mesmo processo)
  Comunicação         | LENTA (via SO: pipes, sockets)| RÁPIDA (acesso direto a variáveis)
  Criação/Troca       | LENTA e CUSTOSA               | RÁPIDA e LEVE
  Falha               | Um trava, os outros não       | Uma trava, o processo inteiro pode travar


-------------------------------------
  ANATOMIA DE UMA THREAD
-------------------------------------
- O que uma thread TEM SÓ PARA ELA:
  * Stack (Pilha): Para suas variáveis locais e chamadas de função. É ISOLADA.
  * Registradores da CPU: Incluindo o Program Counter (PC), que aponta para a instrução atual.

- O que uma thread COMPARTILHA com outras threads do mesmo processo:
  * Heap (Memória Dinâmica): Onde objetos e dados são alocados.
  * Código do Programa: Todas executam o mesmo código-fonte.
  * Dados Globais: Variáveis globais são visíveis para todas.
  * Recursos do SO: Descritores de arquivos, conexões de rede, etc.


-------------------------------------
  CONCORRÊNCIA vs. PARALELISMO
-------------------------------------
- CONCORRÊNCIA: Lidar com várias coisas ao mesmo tempo.
  * Em um único núcleo de CPU, as tarefas são alternadas rapidamente, criando a ILUSÃO de simultaneidade.
  * Ex: Um chef de cozinha que corta legumes, mexe a panela e vigia o forno. Ele está lidando com tudo, mas focando em uma coisa de cada vez.

- PARALELISMO: Fazer várias coisas ao mesmo tempo.
  * Requer múltiplos núcleos de CPU. Duas ou mais tarefas rodam literalmente no mesmo instante.
  * Ex: Dois chefs (dois núcleos) cozinhando dois pratos diferentes ao mesmo tempo.

✅ Concorrência é sobre ESTRUTURA, paralelismo é sobre EXECUÇÃO. Go é excelente para estruturar código concorrente, que pode ou não ser executado em paralelo.


-------------------------------------
  O GRANDE DESAFIO: RACE CONDITIONS (CONDIÇÕES DE CORRIDA)
-------------------------------------
- Ocorre quando duas ou mais threads tentam acessar e modificar o mesmo recurso de memória ao mesmo tempo.
- O resultado final depende da ordem "da sorte" em que as threads são executadas, levando a resultados imprevisíveis e bugs difíceis de rastrear.
- SOLUÇÃO: Sincronização. Usar mecanismos como Mutexes, Semáforos ou, no estilo Go, Channels, para garantir que apenas uma thread acesse o recurso por vez.


-------------------------------------
  A REVOLUÇÃO DO GO: GOROUTINES
-------------------------------------
- Goroutines são as "threads" do Go, mas são muito mais leves e eficientes. Elas NÃO SÃO threads do SO.
- Elas são gerenciadas pelo GO RUNTIME, não diretamente pelo SO.
- CUSTO DE MEMÓRIA:
  * Thread do SO: Inicia com uma stack fixa e grande (~1-2 MB).
  * Goroutine: Inicia com uma stack minúscula e dinâmica (~2 KB) que cresce conforme a necessidade.
- IMPACTO: Você pode ter MILHÕES de goroutines em um único processo, enquanto estaria limitado a alguns milhares de threads do SO. Isso permite um nível de concorrência massivo.


-------------------------------------
  GO x NODE.JS (COMPARAÇÃO)
-------------------------------------
- Go (Goroutines):
  * Modelo de concorrência nativo e central na linguagem (`go func() {}`).
  * Extremamente leves, permitindo alta concorrência.
  * O Go Scheduler gerencia as goroutines de forma preemptiva em um pool de threads do SO, aproveitando múltiplos núcleos naturalmente.

- Node.js (Worker Threads):
  * A concorrência não é o padrão. O JS principal roda em uma única thread (Event Loop).
  * Para paralelismo de CPU, você precisa usar o módulo `worker_threads`.
  * Cada `worker` é uma THREAD REAL do SO, o que os torna mais pesados que goroutines.
  * A comunicação entre workers é mais complexa, baseada na troca de mensagens, pois eles não compartilham memória da mesma forma fácil.


-------------------------------------
  DICAS RÁPIDAS
-------------------------------------
✅ Thread: Execução dentro de um processo, com stack própria mas heap compartilhada.
✅ Race Condition: O principal perigo do multithreading. Duas threads, um recurso, zero regras.
✅ Concorrência (1 CPU): Alternância rápida. Paralelismo (+1 CPU): Execução simultânea.
✅ Goroutine: Uma "thread verde" gerenciada pelo Go. Super leve (2KB stack), super escalável.


-------------------------------------
  EXEMPLO EM GO (RACE CONDITION E SOLUÇÃO)
-------------------------------------
// Este exemplo mostra uma race condition na prática e como corrigi-la.
package main

import (
    "fmt"
    "sync"
    "sync/atomic"
)

func main() {
    var contador int64
    var wg sync.WaitGroup

    // --- Versão com RACE CONDITION ---
    // Lançamos 1000 goroutines, cada uma incrementando o contador 100 vezes.
    // O resultado esperado é 100.000, mas o resultado real será menor.
    wg.Add(1000)
    for i := 0; i < 1000; i++ {
        go func() {
            for j := 0; j < 100; j++ {
                contador++ // Perigoso! Leitura, incremento e escrita não são uma operação única.
            }
            wg.Done()
        }()
    }
    wg.Wait()
    fmt.Printf("Resultado com Race Condition: %d (Incorreto)\n", contador)


    // --- Versão CORRIGIDA com Atomic ---
    // Resetamos o contador para fazer o teste correto.
    contador = 0
    wg.Add(1000)
    for i := 0; i < 1000; i++ {
        go func() {
            for j := 0; j < 100; j++ {
                // atomic.AddInt64 garante que a operação de soma seja atômica,
                // ou seja, indivisível e segura contra concorrência.
                atomic.AddInt64(&contador, 1)
            }
            wg.Done()
        }()
    }
    wg.Wait()
    fmt.Printf("Resultado corrigido com Atomic: %d (Correto)\n", contador)
}